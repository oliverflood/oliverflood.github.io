---
author: Oliver Flood
pubDatetime: 2025-09-23T16:56:12
modDatetime: 2025-09-23T16:56:12
title: "Finding a good cloud dataset"
featured: true
draft: false
tags:
  - ml
  - clouds
description: Trying to building an end-to-end ML project to identify cloud types in phone camera photos. Can we find good data?
---

import Aside from "../../components/Aside.astro";
import { Image } from "astro:assets";
import CCSN_1 from "../../assets/images/CCSN_Ac-N062.jpg";
import CCSN_2 from "../../assets/images/CCSN_Ac-N132.jpg";
import CCSN_3 from "../../assets/images/CCSN_As-N179.jpg";
import CCSN_4 from "../../assets/images/CCSN_Cb-N018.jpg";
import CCSN_5 from "../../assets/images/CCSN_Cc-N034.jpg";
import CCSN_6 from "../../assets/images/CCSN_Ct-N004.jpg";
import CCSN_7 from "../../assets/images/CCSN_Cu-N009.jpg";
import CCSN_8 from "../../assets/images/CCSN_St-N068.jpg";
import CCSN_9 from "../../assets/images/CCSN_St-N123.jpg";
import GLOBE_1 from "../../assets/images/GLOBE_1.jpg";
import GLOBE_2 from "../../assets/images/GLOBE_2.jpg";
import GLOBE_3 from "../../assets/images/GLOBE_3.jpg";
import GLOBE_4 from "../../assets/images/GLOBE_4.jpg";
import GLOBE_5 from "../../assets/images/GLOBE_5.jpg";
import GLOBE_6 from "../../assets/images/GLOBE_6.jpg";
import GLOBE_7 from "../../assets/images/GLOBE_7.jpg";
import GLOBE_8 from "../../assets/images/GLOBE_8.jpg";
import GLOBE_9 from "../../assets/images/GLOBE_9.jpg";

I've been wanting to build an end-to-end ML project for a while now, and I finally had a fun idea: a cloud classifier! [Here's the GitHub repo.](https://github.com/oliverflood/clouds-ml) The end goal is simple: Build an app where you can take a photo of a cloud and get some standard classification of the cloud.

<Aside variant="note">
  Presented here is an retelling of some steps I took while working on this
  project. This post focuses on the first part of my project.
</Aside>

## Table of contents

## Can we do it?

How can we check whether the project is feasible? Well, there are some considerations.

1. **Is there data available online?** <br/>
   The [Cirrus Cumulus Stratus Nimbus (CCSN) dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD) found in [this paper](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2018GL077787) looks good at a first glance. CCSN appears to be a pretty common ground photo dataset used in academic papers, and is also [available on Kaggle](https://www.kaggle.com/datasets/mmichelli/cirrus-cumulus-stratus-nimbus-ccsn-database).

2. **Has it been done before?** <br/>
   In academic papers, yes, but not too many times. One example is this [research paper](https://peerj.com/articles/cs-1779/) which compares different vision models on the CCSN dataset. Another example is this paper on [self-supervised cloud classification](https://journals.ametsoc.org/view/journals/aies/3/1/AIES-D-23-0036.1.xml) from satellite images. I can only find a couple GitHub repos, with the top result being [this one by Marcos Plaza](https://github.com/marcosPlaza/Ground-based-Cloud-Classification-with-Deep-Learning) on CCSN. Out of the handful of apps, almost all are paywalled and wrap a call to ChatGPT asking for a cloud type (what a shame). The best app I've found is the [CloudSpotter app](https://play.google.com/store/apps/details?id=com.cloudappreciationsociety.cloudaday&hl=en_US&pli=1) by the [Cloud Appreciation Society (CAS)](https://cloudappreciationsociety.org/).

3. **Are the compute/storage requirements reasonable?** <br/>
   CCSN is relatively small at 2543 jpg images, with each image averaging around 50kB in size. That's perfectly reasonable to fit on my machine. Deep vision model training runs should take under a couple of hours, which is also reasonable.

This isn't a bad place to start!

<Aside variant="note">
  If only I had known the enormous pain getting good data would be. It was never
  going to be as easy as finding something off Kaggle. But, that's part of the
  fun after all.
</Aside>

## Should we do it?

Well, a goal for the project is to create something original. Of the academic papers that use ground based photos, most use CCSN or data without cloud types like the [SWIMCAT](https://malea.winkler.site/swimcat.html) dataset. This encourages me as focusing on a deployable model is sufficiently original. There are some Kaggle notebooks for the CCSN dataset, but these feel far from a full project. Also, as I'll cover later, CCSN isn't so ideal for my own goal of making an app.

The only _app_ that would deter me from building my own is CloudSpotter, but it has a couple of flaws:

1. No uploading past images.
2. No multi-label classification of clouds.
3. No privacy of the images you upload.
4. No web-based deployment.

The above gives me hope that I can nontrivially improve upon the lucrative cloud classification space. I also know that CloudSpotter pays people to label their data, as a friend told me their Geography PhD professor got offered the job! I can't compete with access to paid labelers and a database of labeled user submissions, and that's totally ok! CloudSpotter is a lovely app, and really does much more than just cloud type identification.

As far as I am aware, I can still work towards making an open source end-to-end cloud identification app using vision models and call it original.

## The CCSN dataset

As stated above, the [CCSN dataset from Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD) is a common academic dataset with 2543 labeled cloud images. This labels include the 10 main cloud genera (cloud groups defined in the [International Cloud Atlas](https://cloudatlas.wmo.int/en/principles-of-cloud-classification-genera.html)) as well as contrails, a type of man-made cloud from airplanes. So CCSN provides a fine space of 11 cloud classes. Importantly, this data is single-label. Each image is tagged with one and only one of the 11 cloud classes available.

<Aside variant="note">
  The 10 main cloud genera are: altocumulus, altostratus, cirrocumulus,
  cirrostratus, cirrus, cumulonimbus, cumulus, nimbostratus, stratocumulus,
  stratus. [Here's a great place to learn
  more.](https://cloudappreciationsociety.org/cloud-library/)
</Aside>

### CCSN shortcomings

The CCSN dataset isn't as good as you might think. The end goal is to deploy this classifier on an app, and so the distribution of cloud photos seen by the final model will be from cell phone cameras and amateur photographers. Additionally, the photos will probably be somewhat _boring_. This is an important point. The CCSN images look like they're ripped straight from the Google Search for respective cloud types, and this means a lot of picturesque, sunset-time, and perfectly framed photos. My guess is that the distribution of cloud images in CCSN is fairly different from the distribution a model might encounter being deployed on an app.

<figure>
  <div class="grid grid-cols-3 gap-1">
    <Image
      src={CCSN_1}
      alt="CCSN altocumulus image 062"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_2}
      alt="CCSN altocumulus image 132"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_3}
      alt="CCSN altostratus image 179"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_4}
      alt="CCSN cumulonimbus image 018"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_5}
      alt="CCSN cirrocumulus image 034"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_6}
      alt="CCSN contrails image 004"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_7}
      alt="CCSN cumulus image 009"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_8}
      alt="CCSN stratus image 068"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_9}
      alt="CCSN stratus image 123"
      class="m-0 block h-auto w-full"
    />
  </div>
  <figcaption>
    Slightly cherry-picked sample of nine CCSN images. These don't resemble the
    honest, hardworking clouds you see in the sky every day.
  </figcaption>
</figure>

<Aside variant="note">
  The actual first dataset I found
  ([SKIPP'D](https://github.com/yuhao-nie/Stanford-solar-forecasting-dataset))
  had whole-sky fisheye lens images from an observatory. Super cool, but not
  ideal for this application!
</Aside>

Well, what can we do about this? We want a dataset that will most closely mimic the expected distribution of cloud images a deployed model will pull from. So, basically, we want mundane phone photos taken from the ground. Fortunately for us, citizen science comes to the rescue!

## NASA GLOBE dataset

The [NASA Global Learning and Observations to Benefit the Environment (GLOBE)](https://www.globe.gov/globe-data) program collects citizen scientist data from around the world and makes it freely accessible. Anyone can volunteer, download the app, and contribute.

Importantly, part of their data includes a sky conditions report where north, south, east, west, and upwards facing photos of the sky are taken. Users are then guided through a cloud identification wizard to report which of the 10 main cloud genera are visible in the sky. The real benefit of the NASA GLOBE dataset comes from the fact that the images appear to match the distribution of random cloud pictures you'd get on an app. Basically, they're just more normal looking.

There also is an enormous amount of GLOBE data. In only about a year's worth of GLOBE data I collected were **334,540** photos of the sky! There is also a great amount of guaranteed geographical & seasonal variety. The GLOBE data has labels for the main 10 cloud types, as well as for fog and contrails. There is loads of other information and metadata collected for each observation in the dataset as well.

<figure>
  <div class="grid grid-cols-3 gap-1">
    <Image
      src={GLOBE_1}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_2}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_3}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_4}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_5}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_6}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_7}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_8}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_9}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
  </div>
  <figcaption>
    Random examples of NASA GLOBE sky conditions images cropped to square shape.
    Hopefully the photos better match the distribution we'd expect from app
    photos. Can you spot the exceedingly rare cloud type above? It is indeed
    bona fide GLOBE data, and finding it absolutely made my day.
  </figcaption>
</figure>

### GLOBE shortcomings

Just like the CCSN dataset, the NASA GLOBE dataset also has some problems.

1. **We only have access to cloud labels per observation.** <br/>
   Put differently, our 5 (North, East, South, West, Up) photos all share one set of labels. So a perfectly clear sky with one cumulus cloud in the North image will essentially label all images as having a cumulus cloud[^1].

2. **The labels are noisy.** <br/>
   The citizen scientists labeling the images have (understandably) made mistakes. While this is to be expected, and even CCSN has plenty of poor labels, these noisy labels are surprisingly prolific in the NASA GLOBE data. If the mistakes were just false negatives (the labeler missed a cirrus cloud, for example) it could be recoverable. But there is also an enormous amount of false positives. For example: labeling an image as the rare cumulonimbus cloud when in fact it is just a lame altocumulus. This really hurts our chances of making a good classifier.

3. **Some images aren't clouds.** <br/>
   This is by far the least important problem, but it's still worth mentioning. There are examples of [near-black screens](https://data.globe.gov/system/photos/2024/07/13/4056674/original.jpg) and [photos of the ground](https://data.globe.gov/system/photos/2025/08/29/4689720/original.jpg) submitted for all observation photos.

{/* Add notes about covariance between cloud labels. */}

<Aside variant="note">
  At this point in the project I got very worried that no data would be good
  enough. In hindsight, CCSN probably would have worked. However, with the help
  of my friend Heather, I reached out [Marilé Colón
  Robles](https://science.larc.nasa.gov/people/marile-colon-robles/), a NASA
  Langley scientist on the GLOBE team! She pointed me to [NASA GLOBE CLOUD
  GAZE](https://www.zooniverse.org/projects/nasaglobe/nasa-globe-cloud-gaze)
  which I'd completely missed on the [GLOBE
  website](https://observer.globe.gov/get-data/clouds-data#cloudgaze) (oops).
  Thank you Heather and Marilé!
</Aside>

## NASA CLOUD GAZE dataset

The [NASA GLOBE CLOUD GAZE](https://www.zooniverse.org/projects/nasaglobe/nasa-globe-cloud-gaze) is a subset of the NASA GLOBE data born from a collaboration between NASA and the citizen science platform Zooniverse. How GAZE works is that NASA GLOBE photos are reviewed by multiple citizen scientists, only being officially classified and retired when:

1. **Consenus among labelers is reached.** All labelers agree on on what types of clouds are in the photo.
2. **Enough classifications are taken.** Eight labelers or 80% of those that classified the photo agreed on the result.

This ensemble of labelers gets us much much higher quality labels than the standard GLOBE data. Additionally, labelers can mark photos as having a blocked view, being blurry, or taken at night, and we can safely exclude these from our own training data. In total, GAZE gets us 13,500 well-labeled photos. While this is nowhere near as many as GLOBE, it is significantly more than the 2543 photos in CCSN.

<Aside variant="note">
  The GAZE data was actually only an 18-month prototype funded by the [NASA
  Citizen Science for Earth Systems
  Program](https://www.earthdata.nasa.gov/about/competitive-programs/csesp).
  Unforunately, the project wasn't able to secure a full implementation, which
  would have granted an additional 3 years of funding. A real shame, imagine
  what could have been!
</Aside>

One last very important detail is that while GAZE selected _observations_ from the GLOBE data, it has labels _per-photo_ for each photo in the observation. That's massive! GAZE solves <u>all three problems</u> from the regular GLOBE data. GAZE also has 5x as many photos as CCSN and the photos better match our assumption about the distribution of cloud photos in the wild. So the GAZE data is perfect, right?

### GAZE shortcomings

The GAZE dataset, while amazing, is not perfect. The biggest issue is that the label space is different. Instead of the 10 cloud genera outlined by the International Cloud Association, the GAZE data has the following 7 labels for each photograph:

1. `clearsky`
2. `cirrus or cirrostratus`
3. `cirrocumulus or altocumulus`
4. `altostratus or stratus`
5. `stratocumulus`
6. `cumulus`
7. `cumulonimbus`

This is quite different from CCSN or GLOBE. Firstly, there is an explicit label for a clear sky. Additionally, cirrocumulus and altocumulus were combined into one label. This makes some sense as they are easy to confuse, both being a layer of small cloudlets (_cirro_ clouds being the highest altitude while _alto_ clouds are mid-range). The altostratus and stratus labels are also combined, and similarly they are both blankets of cloud primarily differentiated by height level. The combination of cirrus and cirrostratus is a little more confusing. They are both very high clouds and it's possibly they are mislabeled frequently. What really confounds me is that there is no label for [nimbostratus](https://cloudappreciationsociety.org/cloud-library/nimbostratus/), the thick, gray, and somewhat depressing raincloud.

There are [more labels available in GAZE](https://observer.globe.gov/documents/19589576/60147054/CLOUD+GAZE+Data+Description+v2.0.pdf) such as contrails, smoke, and dust, but let's ignore these as so few of the images actually have such labels. I know, I know. Contrail classification is hard to let go, as contrails are indeed clouds. However, to limit project scope, we'll have to keep it all-natural for now.

This different labeling gives the GAZE data a unique tradeoff. We can't classify as many cloud types but get enormous advantages in data quality. I think it's a good idea to try and use the GAZE data for the time being. Primarily, the GAZE data gives us high quality data from a good distribution. Additionally, as far as I can tell, nobody else has tried training a classifier on the GAZE data! This is nice, as there are a couple of academic/Kaggle classifiers trained on CCSN.

## Conclusion

Well, looks like GAZE is good enough for a first try. Tune in for another post in the near (?) future, when I feel the random urge to write again!

{/* We can strech this by using transformations like random resized crops, slight rotations, color jitter, and horizontal flips. This is a nice advantage of working on a computer vision problem, as these transformations generally preserve the original label but give us sufficiently different data so our model doesn't overfit. */}

## Footnotes

[^1]: I am aware of [multiple instance learning](https://en.wikipedia.org/wiki/Multiple_instance_learning) which bags together multiple instances (of cloud photos) with an observation level label. However, even with such methods I'm not convinced the raw NASA GLOBE dataset would work well.
