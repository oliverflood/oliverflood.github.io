---
author: Oliver Flood
pubDatetime: 2025-09-23T16:56:12
modDatetime: 2025-09-23T16:56:12
title: "The cloud classifier odyssey"
slug: cloud-classifier-odyssey
featured: true
draft: false
tags:
  - ml
  - clouds
description: My journey of building an end-to-end machine learning project to identify cloud types in phone camera photos.
---

import Aside from "../../components/Aside.astro";
import { Image } from "astro:assets";
import CCSN_1 from "../../assets/images/CCSN_Ac-N062.jpg";
import CCSN_2 from "../../assets/images/CCSN_Ac-N132.jpg";
import CCSN_3 from "../../assets/images/CCSN_As-N179.jpg";
import CCSN_4 from "../../assets/images/CCSN_Cb-N018.jpg";
import CCSN_5 from "../../assets/images/CCSN_Cc-N034.jpg";
import CCSN_6 from "../../assets/images/CCSN_Ct-N004.jpg";
import CCSN_7 from "../../assets/images/CCSN_Cu-N009.jpg";
import CCSN_8 from "../../assets/images/CCSN_St-N068.jpg";
import CCSN_9 from "../../assets/images/CCSN_St-N123.jpg";
import GLOBE_1 from "../../assets/images/GLOBE_1.jpg";
import GLOBE_2 from "../../assets/images/GLOBE_2.jpg";
import GLOBE_3 from "../../assets/images/GLOBE_3.jpg";
import GLOBE_4 from "../../assets/images/GLOBE_4.jpg";
import GLOBE_5 from "../../assets/images/GLOBE_5.jpg";
import GLOBE_6 from "../../assets/images/GLOBE_6.jpg";
import GLOBE_7 from "../../assets/images/GLOBE_7.jpg";
import GLOBE_8 from "../../assets/images/GLOBE_8.jpg";
import GLOBE_9 from "../../assets/images/GLOBE_9.jpg";

I've been wanting to build an end-to-end ML project for a while now, and I finally had a good idea that seemed relatively original: a cloud classifier!

<Aside variant="note">
  Presented here is the distilled effort of lots of Jupyter notebooks &
  exploration, and is much cleaner than the real path I took while working on
  this. Mistakes I made and rabbit holes I went down are ocassionally pointed
  out like this.
</Aside>

The end goal is simple: Build an app where you can take a photo of a cloud and get some standard classification of the cloud.

## Can we do it?

How can we check whether the project is feasible? Well, there are some considerations.

1. **Is there data available online?** <br/>
   The [Cirrus Cumulus Stratus Nimbus (CCSN) dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD) found in [this paper](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2018GL077787) looks good at a first glance. CCSN appears to be a pretty common ground photo dataset used in academic papers, and is also [available on Kaggle](https://www.kaggle.com/datasets/mmichelli/cirrus-cumulus-stratus-nimbus-ccsn-database).

2. **Has it been done before?** <br/>
   In academic papers, yes, but not too many times. One example is this [research paper](https://peerj.com/articles/cs-1779/) which compares different vision models on the CCSN dataset. Another example is this paper on [self-supervised cloud classification](https://journals.ametsoc.org/view/journals/aies/3/1/AIES-D-23-0036.1.xml) from satellite images. I can only find a couple GitHub repos, with the top result being [this one by Marcos Plaza](https://github.com/marcosPlaza/Ground-based-Cloud-Classification-with-Deep-Learning) on CCSN. Out of the handful of apps, almost all are paywalled and wrap a call to ChatGPT asking for a cloud type (what a shame). The best app I've found is the [CloudSpotter app](https://play.google.com/store/apps/details?id=com.cloudappreciationsociety.cloudaday&hl=en_US&pli=1) by the [Cloud Appreciation Society (CAS)](https://cloudappreciationsociety.org/).

3. **Are the compute/storage requirements reasonable?** <br/>
   CCSN is relatively small at 2543 jpg images, with each image averaging around 50kB in size. That's perfectly reasonable to fit on my machine. Deep vision model training runs should take under a couple of hours, which is also reasonable.

This isn't a bad place to start!

<Aside variant="note">
  If only I had known the enormous pain getting good data would be. It was never
  going to be as easy as finding something off Kaggle. But, that's part of the
  fun after all.
</Aside>

## Should we do it?

Well, a personal goal of mine was to create something original. The academic papers don't deter me so much, since the only ground-based images use CCSN or data without cloud types like the [SWIMCAT](https://malea.winkler.site/swimcat.html) dataset. There are some notebooks on Kaggle for CCSN but, as I'll cover later, CCSN isn't so ideal for my own goal of making an app.

The only _app_ that would deter me from building my own is CloudSpotter, but it has a couple of flaws:

1. No uploading past images.
2. No multi-label classification of clouds.
3. No privacy of the images you upload.
4. No web-based deployment (I can't be bothered to take out my phone all the time).

The above gives me hope that I can nontrivially improve upon the lucrative cloud classification space. I also know that CloudSpotter pays people to label their data, as a friend told me their Geography PhD professor got offered the job! I can't compete with access to paid labelers and a database of labeled user submissions, and that's totally ok! CloudSpotter is a lovely app, and really does much more than just cloud type identification.

As far as I am aware, I can still work towards making an open source end-to-end cloud identification app and call it original.

## The CCSN dataset

As stated above, the [CCSN dataset from Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD) is a common academic dataset. This dataset includes the 10 main cloud genera (cloud groups defined in the [International Cloud Atlas](https://cloudatlas.wmo.int/en/principles-of-cloud-classification-genera.html)) as well as contrails, a type of man-made cloud from airplanes. So CCSN provides a fine space of 11 cloud classes. Importantly, note that this data is single-label, meaning that each image is tagged with one and only one of the 11 cloud classes available.

<Aside variant="note">
  The 10 main cloud genera are: altocumulus, altostratus, cirrocumulus,
  cirrostratus, cirrus, cumulonimbus, cumulus, nimbostratus, stratocumulus,
  stratus.
</Aside>

### CCSN shortcomings

The CCSN dataset isn't as good as you might think. The end goal is to deploy this classifier on an app, and so the distribution of cloud photos seen by the final model will be from cell phone cameras and amateur photographers. Additionally, the photos will probably be somewhat _boring_. This is an important point. The CCSN images look like they're ripped straight from the Google Search for respective cloud types, and this means a lot of picturesque, sunset-time, and perfectly framed photos. My guess is that the distribution of cloud images in CCSN is fairly different from the distribution a model might encounter being deployed on an app.

<figure>
  <div class="grid grid-cols-3 gap-1">
    <Image
      src={CCSN_1}
      alt="CCSN altocumulus image 062"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_2}
      alt="CCSN altocumulus image 132"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_3}
      alt="CCSN altostratus image 179"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_4}
      alt="CCSN cumulonimbus image 018"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_5}
      alt="CCSN cirrocumulus image 034"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_6}
      alt="CCSN contrails image 004"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_7}
      alt="CCSN cumulus image 009"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_8}
      alt="CCSN stratus image 068"
      class="m-0 block h-auto w-full"
    />
    <Image
      src={CCSN_9}
      alt="CCSN stratus image 123"
      class="m-0 block h-auto w-full"
    />
  </div>
  <figcaption>
    Slightly cherry-picked sample of nine CCSN images. These don't resemble the
    honest, hardworking clouds you see in the sky every day.
  </figcaption>
</figure>

<Aside variant="note">
  The actual first dataset I found
  ([SKIPP'D](https://github.com/yuhao-nie/Stanford-solar-forecasting-dataset))
  had whole-sky fisheye lens images from an observatory. Super cool, but not
  ideal for this application!
</Aside>

Well, what can we do about this? We want a dataset that will most closely mimic the expected distribution of cloud images a deployed model will pull from. So, basically, we want crappy phone photos taken from the ground. Fortunately for us, citizen science comes to the rescue!

## NASA GLOBE dataset

The [NASA Global Learning and Observations to Benefit the Environment (GLOBE)](https://www.globe.gov/globe-data) program collects citizen scientist data from around the world and makes it freely accessible. Anyone can volunteer, download the app, and contribute, which is pretty awesome.

Importantly, part of their data includes a sky conditions report where north, south, east, west, and upwards facing photos of the sky are taken. Users are then guided through a cloud identification wizard to report which of the 10 main cloud genera are visible in the sky. The real benefit of the NASA GLOBE dataset comes from the fact that the images appear to match the distribution of random cloud pictures you'd get on an app. Basically, they're just more normal looking.

There is also an enormous amount of GLOBE data. In only about a year's worth of GLOBE data I collected were **334,540** photos of the sky! There is also a great amount of guaranteed geographical & seasonal variety.

<figure>
  <div class="grid grid-cols-3 gap-1">
    <Image
      src={GLOBE_1}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_2}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_3}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_4}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_5}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_6}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_7}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_8}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
    <Image
      src={GLOBE_9}
      alt="GLOBE dataset cloud image"
      class="m-0 block aspect-square h-auto w-full"
    />
  </div>
  <figcaption>
    Random examples of NASA GLOBE sky conditions images cropped to square shape.
    Hopefully the photos better match the distribution we'd expect from app
    photos. Can you spot the exceedingly rare cloud type above? It is indeed
    bona fide GLOBE data, and finding it absolutely made my day.
  </figcaption>
</figure>

### NASA GLOBE shortcomings

Just like the CCSN dataset, the NASA GLOBE dataset also has some problems.

1. **We only have access to cloud labels per observation.** <br/>
   Put differently, our 5 (North, East, South, West, Up) photos all share one set of labels. So a perfectly clear sky with one cumulus cloud in the North image will essentially label all images as having a cumulus cloud[^1].

2. **The labels are noisy.** <br/>
   The citizen scientists labeling the images have (understandably) made mistakes. While this is to be expected, and even CCSN has plenty of poor labels, these noisy labels are surprisingly prolific in the NASA GLOBE data. If the mistakes were just false negatives (the labeler missed a cirrus cloud, for example) it could be recoverable. But there is also an enormous amount of false positives. For example: labeling an image as the rare cumulonimbus cloud when in fact it is just a lame altocumulus. This really hurts our chances of making a good classifier.

3. **Some images aren't clouds.** <br/>
   This is by far the least important problem, but it's still worth mentioning. There are examples of [near-black screens](https://data.globe.gov/system/photos/2024/07/13/4056674/original.jpg) and [photos of the ground](https://data.globe.gov/system/photos/2025/08/29/4689720/original.jpg) submitted for all observation photos.

<Aside variant="note">
  At this point in the project I got very worried that no data would be good
  enough. In hindsight, CCSN probably would have worked. However, with the help
  of my friend Heather, I reached out [Marilé Colón
  Robles](https://science.larc.nasa.gov/people/marile-colon-robles/), a NASA
  Langley scientist on the GLOBE team! She pointed me to [NASA GLOBE CLOUD
  GAZE](https://www.zooniverse.org/projects/nasaglobe/nasa-globe-cloud-gaze)
  which I'd completely missed on the [GLOBE
  website](https://observer.globe.gov/get-data/clouds-data#cloudgaze) (oops).
  Thank you Heather and Marilé!
</Aside>

## NASA CLOUD GAZE dataset

The [NASA GLOBE CLOUD GAZE](https://www.zooniverse.org/projects/nasaglobe/nasa-globe-cloud-gaze) dataset was born from a collaboration between NASA and the citizen science platform Zooniverse.

<Aside variant="oops">
  Sorry! This post is incomplete, as the project is still a work in progress.
  Check back later!
</Aside>

## Footnotes

[^1]: I am aware of [multiple instance learning](https://en.wikipedia.org/wiki/Multiple_instance_learning) which bags together multiple instances for an observation level label. However, even with this fix, I'm not convinced the raw NASA GLOBE dataset could work well. Definitely worth looking into, though.
